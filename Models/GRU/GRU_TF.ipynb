{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 21:31:28.788325: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-25 21:31:28.806144: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-25 21:31:28.806188: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-25 21:31:28.806199: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-25 21:31:28.810155: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-25 21:31:29.282163: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pylab as rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import matplotlib \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GRU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from  sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>p_sentiment</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>unrate</th>\n",
       "      <th>psr</th>\n",
       "      <th>m2</th>\n",
       "      <th>dspic</th>\n",
       "      <th>pce</th>\n",
       "      <th>reer</th>\n",
       "      <th>ir</th>\n",
       "      <th>ffer</th>\n",
       "      <th>tcs</th>\n",
       "      <th>indpro</th>\n",
       "      <th>ccpi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>27.847500</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>26.837500</td>\n",
       "      <td>27.332500</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>15.629000</td>\n",
       "      <td>15.737500</td>\n",
       "      <td>15.348000</td>\n",
       "      <td>15.426000</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.883473</td>\n",
       "      <td>26.378078</td>\n",
       "      <td>26.490770</td>\n",
       "      <td>26.133251</td>\n",
       "      <td>26.168653</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.908735</td>\n",
       "      <td>26.629999</td>\n",
       "      <td>26.790001</td>\n",
       "      <td>26.393999</td>\n",
       "      <td>26.477501</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.804051</td>\n",
       "      <td>46.660000</td>\n",
       "      <td>47.419998</td>\n",
       "      <td>46.540001</td>\n",
       "      <td>46.759998</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7531</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.748412</td>\n",
       "      <td>93.699997</td>\n",
       "      <td>94.199997</td>\n",
       "      <td>92.030998</td>\n",
       "      <td>92.344498</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.676151</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>67.650002</td>\n",
       "      <td>66.700996</td>\n",
       "      <td>66.806999</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.705876</td>\n",
       "      <td>67.840500</td>\n",
       "      <td>67.849998</td>\n",
       "      <td>66.891998</td>\n",
       "      <td>66.985497</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.762997</td>\n",
       "      <td>158.990005</td>\n",
       "      <td>159.020004</td>\n",
       "      <td>156.729996</td>\n",
       "      <td>157.589996</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.588330</td>\n",
       "      <td>28.586000</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>27.284000</td>\n",
       "      <td>27.646667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7536 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date ticker_symbol  p_sentiment        Open        High  \\\n",
       "0     2015-01-02          AAPL     0.857156   27.847500   27.860001   \n",
       "1     2015-01-02          AMZN     0.731959   15.629000   15.737500   \n",
       "2     2015-01-02          GOOG     0.883473   26.378078   26.490770   \n",
       "3     2015-01-02         GOOGL     0.908735   26.629999   26.790001   \n",
       "4     2015-01-02          MSFT     0.804051   46.660000   47.419998   \n",
       "...          ...           ...          ...         ...         ...   \n",
       "7531  2019-12-30          AMZN     0.748412   93.699997   94.199997   \n",
       "7532  2019-12-30          GOOG     0.676151   67.500000   67.650002   \n",
       "7533  2019-12-30         GOOGL     0.705876   67.840500   67.849998   \n",
       "7534  2019-12-30          MSFT     0.762997  158.990005  159.020004   \n",
       "7535  2019-12-30          TSLA     0.588330   28.586000   28.600000   \n",
       "\n",
       "             Low       Close  unrate  psr       m2    dspic      pce    reer  \\\n",
       "0      26.837500   27.332500     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "1      15.348000   15.426000     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "2      26.133251   26.168653     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "3      26.393999   26.477501     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "4      46.540001   46.759998     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "...          ...         ...     ...  ...      ...      ...      ...     ...   \n",
       "7531   92.030998   92.344498     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7532   66.700996   66.806999     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7533   66.891998   66.985497     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7534  156.729996  157.589996     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7535   27.284000   27.646667     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "\n",
       "            ir      ffer        tcs    indpro     ccpi  \n",
       "0     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "1     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "2     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "3     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "4     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "...        ...       ...        ...       ...      ...  \n",
       "7531  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7532  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7533  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7534  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7535  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "\n",
       "[7536 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/home/j/usfq/tesis/StockPredictionModels/Data/Complete.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn date into unix time\n",
    "#df['Date'] = pd.to_datetime(df['Date'])\n",
    "#df['Date'] = df['Date'].apply(lambda x: x.timestamp())\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL (1252, 17)\n",
      "            Date  p_sentiment       Open       High        Low      Close  \\\n",
      "0     2015-01-02     0.857156  27.847500  27.860001  26.837500  27.332500   \n",
      "1     2015-01-05     0.744531  27.072500  27.162500  26.352501  26.562500   \n",
      "2     2015-01-06     0.769826  26.635000  26.857500  26.157499  26.565001   \n",
      "3     2015-01-07     0.773995  26.799999  27.049999  26.674999  26.937500   \n",
      "4     2015-01-08     0.770458  27.307501  28.037500  27.174999  27.972500   \n",
      "...          ...          ...        ...        ...        ...        ...   \n",
      "1246  2019-12-20     0.775477  70.557503  70.662498  69.639999  69.860001   \n",
      "1247  2019-12-23     0.759453  70.132500  71.062500  70.092499  71.000000   \n",
      "1248  2019-12-24     0.742264  71.172501  71.222504  70.730003  71.067497   \n",
      "1249  2019-12-26     0.670220  71.205002  72.495003  71.175003  72.477501   \n",
      "1250  2019-12-27     0.760582  72.779999  73.492500  72.029999  72.449997   \n",
      "\n",
      "      unrate  psr       m2    dspic      pce    reer        ir      ffer  \\\n",
      "0        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "1        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "2        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "3        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "4        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "...      ...  ...      ...      ...      ...     ...       ...       ...   \n",
      "1246     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1247     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1248     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1249     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1250     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "\n",
      "            tcs    indpro     ccpi  \n",
      "0     1069010.0  102.8479  239.811  \n",
      "1     1069010.0  102.8479  239.811  \n",
      "2     1069010.0  102.8479  239.811  \n",
      "3     1069010.0  102.8479  239.811  \n",
      "4     1069010.0  102.8479  239.811  \n",
      "...         ...       ...      ...  \n",
      "1246  1458485.0  101.6179  265.651  \n",
      "1247  1458485.0  101.6179  265.651  \n",
      "1248  1458485.0  101.6179  265.651  \n",
      "1249  1458485.0  101.6179  265.651  \n",
      "1250  1458485.0  101.6179  265.651  \n",
      "\n",
      "[1251 rows x 17 columns]\n",
      "AMZN (1257, 17)\n",
      "            Date  p_sentiment       Open       High        Low      Close  \\\n",
      "0     2015-01-02     0.731959  15.629000  15.737500  15.348000  15.426000   \n",
      "1     2015-01-05     0.696571  15.350500  15.419000  15.042500  15.109500   \n",
      "2     2015-01-06     0.640295  15.112000  15.150000  14.619000  14.764500   \n",
      "3     2015-01-07     0.654047  14.875000  15.064000  14.766500  14.921000   \n",
      "4     2015-01-08     0.653703  15.016000  15.157000  14.805500  15.023000   \n",
      "...          ...          ...        ...        ...        ...        ...   \n",
      "1251  2019-12-20     0.713209  89.981003  90.148499  89.122498  89.324997   \n",
      "1252  2019-12-23     0.788889  89.413002  89.650002  89.225502  89.650002   \n",
      "1253  2019-12-24     0.749017  89.690498  89.778503  89.378998  89.460503   \n",
      "1254  2019-12-26     0.765611  90.050499  93.523003  89.974998  93.438499   \n",
      "1255  2019-12-27     0.738419  94.146004  95.070000  93.300499  93.489998   \n",
      "\n",
      "      unrate  psr       m2    dspic      pce    reer        ir      ffer  \\\n",
      "0        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "1        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "2        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "3        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "4        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "...      ...  ...      ...      ...      ...     ...       ...       ...   \n",
      "1251     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1252     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1253     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1254     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1255     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "\n",
      "            tcs    indpro     ccpi  \n",
      "0     1069010.0  102.8479  239.811  \n",
      "1     1069010.0  102.8479  239.811  \n",
      "2     1069010.0  102.8479  239.811  \n",
      "3     1069010.0  102.8479  239.811  \n",
      "4     1069010.0  102.8479  239.811  \n",
      "...         ...       ...      ...  \n",
      "1251  1458485.0  101.6179  265.651  \n",
      "1252  1458485.0  101.6179  265.651  \n",
      "1253  1458485.0  101.6179  265.651  \n",
      "1254  1458485.0  101.6179  265.651  \n",
      "1255  1458485.0  101.6179  265.651  \n",
      "\n",
      "[1256 rows x 17 columns]\n",
      "GOOG (1256, 17)\n",
      "            Date  p_sentiment       Open       High        Low      Close  \\\n",
      "0     2015-01-02     0.883473  26.378078  26.490770  26.133251  26.168653   \n",
      "1     2015-01-05     0.842274  26.091366  26.144720  25.582764  25.623152   \n",
      "2     2015-01-06     0.767560  25.679497  25.738087  24.983908  25.029282   \n",
      "3     2015-01-07     0.726427  25.280592  25.292759  24.914099  24.986401   \n",
      "4     2015-01-08     0.814441  24.831326  25.105074  24.482782  25.065184   \n",
      "...          ...          ...        ...        ...        ...        ...   \n",
      "1250  2019-12-20     0.670623  68.167503  68.181999  67.449997  67.479500   \n",
      "1251  2019-12-23     0.774953  67.793503  67.989998  67.325500  67.442001   \n",
      "1252  2019-12-24     0.698763  67.425003  67.513000  67.139000  67.178001   \n",
      "1253  2019-12-26     0.797474  67.308502  68.066353  67.223503  68.019997   \n",
      "1254  2019-12-27     0.738640  68.149498  68.226501  67.465500  67.594498   \n",
      "\n",
      "      unrate  psr       m2    dspic      pce    reer        ir      ffer  \\\n",
      "0        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "1        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "2        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "3        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "4        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "...      ...  ...      ...      ...      ...     ...       ...       ...   \n",
      "1250     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1251     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1252     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1253     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1254     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "\n",
      "            tcs    indpro     ccpi  \n",
      "0     1069010.0  102.8479  239.811  \n",
      "1     1069010.0  102.8479  239.811  \n",
      "2     1069010.0  102.8479  239.811  \n",
      "3     1069010.0  102.8479  239.811  \n",
      "4     1069010.0  102.8479  239.811  \n",
      "...         ...       ...      ...  \n",
      "1250  1458485.0  101.6179  265.651  \n",
      "1251  1458485.0  101.6179  265.651  \n",
      "1252  1458485.0  101.6179  265.651  \n",
      "1253  1458485.0  101.6179  265.651  \n",
      "1254  1458485.0  101.6179  265.651  \n",
      "\n",
      "[1255 rows x 17 columns]\n",
      "GOOGL (1257, 17)\n",
      "            Date  p_sentiment       Open       High        Low      Close  \\\n",
      "0     2015-01-02     0.908735  26.629999  26.790001  26.393999  26.477501   \n",
      "1     2015-01-05     0.882317  26.357500  26.399500  25.887501  25.973000   \n",
      "2     2015-01-06     0.791379  26.025000  26.060499  25.277500  25.332001   \n",
      "3     2015-01-07     0.721880  25.547501  25.574499  25.182501  25.257500   \n",
      "4     2015-01-08     0.730047  25.075500  25.375000  24.750999  25.345501   \n",
      "...          ...          ...        ...        ...        ...        ...   \n",
      "1251  2019-12-20     0.768590  68.154999  68.199997  67.536499  67.560997   \n",
      "1252  2019-12-23     0.716898  67.936501  68.092499  67.400002  67.531502   \n",
      "1253  2019-12-24     0.764184  67.510498  67.600502  67.208504  67.221497   \n",
      "1254  2019-12-26     0.826140  67.327499  68.160004  67.275497  68.123497   \n",
      "1255  2019-12-27     0.698837  68.199997  68.352501  67.650002  67.732002   \n",
      "\n",
      "      unrate  psr       m2    dspic      pce    reer        ir      ffer  \\\n",
      "0        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "1        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "2        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "3        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "4        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "...      ...  ...      ...      ...      ...     ...       ...       ...   \n",
      "1251     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1252     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1253     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1254     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1255     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "\n",
      "            tcs    indpro     ccpi  \n",
      "0     1069010.0  102.8479  239.811  \n",
      "1     1069010.0  102.8479  239.811  \n",
      "2     1069010.0  102.8479  239.811  \n",
      "3     1069010.0  102.8479  239.811  \n",
      "4     1069010.0  102.8479  239.811  \n",
      "...         ...       ...      ...  \n",
      "1251  1458485.0  101.6179  265.651  \n",
      "1252  1458485.0  101.6179  265.651  \n",
      "1253  1458485.0  101.6179  265.651  \n",
      "1254  1458485.0  101.6179  265.651  \n",
      "1255  1458485.0  101.6179  265.651  \n",
      "\n",
      "[1256 rows x 17 columns]\n",
      "MSFT (1257, 17)\n",
      "            Date  p_sentiment        Open        High         Low       Close  \\\n",
      "0     2015-01-02     0.804051   46.660000   47.419998   46.540001   46.759998   \n",
      "1     2015-01-05     0.777896   46.369999   46.730000   46.250000   46.330002   \n",
      "2     2015-01-06     0.757679   46.380001   46.750000   45.540001   45.650002   \n",
      "3     2015-01-07     0.870317   45.980000   46.459999   45.490002   46.230000   \n",
      "4     2015-01-08     0.797476   46.750000   47.750000   46.720001   47.590000   \n",
      "...          ...          ...         ...         ...         ...         ...   \n",
      "1251  2019-12-20     0.733492  157.350006  158.490005  156.289993  157.410004   \n",
      "1252  2019-12-23     0.741044  158.119995  158.119995  157.270004  157.410004   \n",
      "1253  2019-12-24     0.680918  157.479996  157.710007  157.119995  157.380005   \n",
      "1254  2019-12-26     0.727596  157.559998  158.729996  157.399994  158.669998   \n",
      "1255  2019-12-27     0.757561  159.449997  159.550003  158.220001  158.960007   \n",
      "\n",
      "      unrate  psr       m2    dspic      pce    reer        ir      ffer  \\\n",
      "0        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "1        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "2        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "3        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "4        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "...      ...  ...      ...      ...      ...     ...       ...       ...   \n",
      "1251     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1252     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1253     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1254     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1255     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "\n",
      "            tcs    indpro     ccpi  \n",
      "0     1069010.0  102.8479  239.811  \n",
      "1     1069010.0  102.8479  239.811  \n",
      "2     1069010.0  102.8479  239.811  \n",
      "3     1069010.0  102.8479  239.811  \n",
      "4     1069010.0  102.8479  239.811  \n",
      "...         ...       ...      ...  \n",
      "1251  1458485.0  101.6179  265.651  \n",
      "1252  1458485.0  101.6179  265.651  \n",
      "1253  1458485.0  101.6179  265.651  \n",
      "1254  1458485.0  101.6179  265.651  \n",
      "1255  1458485.0  101.6179  265.651  \n",
      "\n",
      "[1256 rows x 17 columns]\n",
      "TSLA (1257, 17)\n",
      "            Date  p_sentiment       Open       High        Low      Close  \\\n",
      "0     2015-01-02     0.741818  14.858000  14.883333  14.217333  14.620667   \n",
      "1     2015-01-05     0.646626  14.303333  14.433333  13.810667  14.006000   \n",
      "2     2015-01-06     0.696584  14.004000  14.280000  13.614000  14.085333   \n",
      "3     2015-01-07     0.654833  14.223333  14.318667  13.985333  14.063333   \n",
      "4     2015-01-08     0.615611  14.187333  14.253333  14.000667  14.041333   \n",
      "...          ...          ...        ...        ...        ...        ...   \n",
      "1251  2019-12-20     0.586239  27.352667  27.533333  26.679333  27.039333   \n",
      "1252  2019-12-23     0.589381  27.452000  28.134001  27.333332  27.948000   \n",
      "1253  2019-12-24     0.643900  27.890667  28.364668  27.512667  28.350000   \n",
      "1254  2019-12-26     0.601846  28.527332  28.898666  28.423332  28.729334   \n",
      "1255  2019-12-27     0.563272  29.000000  29.020666  28.407333  28.691999   \n",
      "\n",
      "      unrate  psr       m2    dspic      pce    reer        ir      ffer  \\\n",
      "0        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "1        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "2        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "3        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "4        5.7  8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839   \n",
      "...      ...  ...      ...      ...      ...     ...       ...       ...   \n",
      "1251     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1252     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1253     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1254     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "1255     3.6  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968   \n",
      "\n",
      "            tcs    indpro     ccpi  \n",
      "0     1069010.0  102.8479  239.811  \n",
      "1     1069010.0  102.8479  239.811  \n",
      "2     1069010.0  102.8479  239.811  \n",
      "3     1069010.0  102.8479  239.811  \n",
      "4     1069010.0  102.8479  239.811  \n",
      "...         ...       ...      ...  \n",
      "1251  1458485.0  101.6179  265.651  \n",
      "1252  1458485.0  101.6179  265.651  \n",
      "1253  1458485.0  101.6179  265.651  \n",
      "1254  1458485.0  101.6179  265.651  \n",
      "1255  1458485.0  101.6179  265.651  \n",
      "\n",
      "[1256 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "#generate new dataframes for each ticker_symbol\n",
    "df_dict={}\n",
    "for key in df['ticker_symbol'].unique():\n",
    "    df_dict[key]=df[df['ticker_symbol']==key]\n",
    "    df_dict[key]=df_dict[key].drop(columns=['ticker_symbol'])\n",
    "    df_dict[key]=df_dict[key].sort_values(by=['Date']).reset_index(drop=True)\n",
    "    #df_dict[key]=df_dict[key].drop(columns=['Date'])\n",
    "    print(key,df_dict[key].shape)\n",
    "    print(df_dict[key].head(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker='AAPL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>p_sentiment</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>unrate</th>\n",
       "      <th>psr</th>\n",
       "      <th>m2</th>\n",
       "      <th>dspic</th>\n",
       "      <th>pce</th>\n",
       "      <th>reer</th>\n",
       "      <th>ir</th>\n",
       "      <th>ffer</th>\n",
       "      <th>tcs</th>\n",
       "      <th>indpro</th>\n",
       "      <th>ccpi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>27.847500</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>26.837500</td>\n",
       "      <td>27.332500</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.8815</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>0.744531</td>\n",
       "      <td>27.072500</td>\n",
       "      <td>27.162500</td>\n",
       "      <td>26.352501</td>\n",
       "      <td>26.562500</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.8815</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>0.769826</td>\n",
       "      <td>26.635000</td>\n",
       "      <td>26.857500</td>\n",
       "      <td>26.157499</td>\n",
       "      <td>26.565001</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.8815</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>0.773995</td>\n",
       "      <td>26.799999</td>\n",
       "      <td>27.049999</td>\n",
       "      <td>26.674999</td>\n",
       "      <td>26.937500</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.8815</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>0.770458</td>\n",
       "      <td>27.307501</td>\n",
       "      <td>28.037500</td>\n",
       "      <td>27.174999</td>\n",
       "      <td>27.972500</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.8815</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  p_sentiment       Open       High        Low      Close  \\\n",
       "0  2015-01-02     0.857156  27.847500  27.860001  26.837500  27.332500   \n",
       "1  2015-01-05     0.744531  27.072500  27.162500  26.352501  26.562500   \n",
       "2  2015-01-06     0.769826  26.635000  26.857500  26.157499  26.565001   \n",
       "3  2015-01-07     0.773995  26.799999  27.049999  26.674999  26.937500   \n",
       "4  2015-01-08     0.770458  27.307501  28.037500  27.174999  27.972500   \n",
       "\n",
       "   unrate  psr       m2    dspic      pce    reer      ir      ffer  \\\n",
       "0     5.7  8.0  11759.1  13224.7  12036.5  106.11  1.8815  0.114839   \n",
       "1     5.7  8.0  11759.1  13224.7  12036.5  106.11  1.8815  0.114839   \n",
       "2     5.7  8.0  11759.1  13224.7  12036.5  106.11  1.8815  0.114839   \n",
       "3     5.7  8.0  11759.1  13224.7  12036.5  106.11  1.8815  0.114839   \n",
       "4     5.7  8.0  11759.1  13224.7  12036.5  106.11  1.8815  0.114839   \n",
       "\n",
       "         tcs    indpro     ccpi  \n",
       "0  1069010.0  102.8479  239.811  \n",
       "1  1069010.0  102.8479  239.811  \n",
       "2  1069010.0  102.8479  239.811  \n",
       "3  1069010.0  102.8479  239.811  \n",
       "4  1069010.0  102.8479  239.811  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df_dict[ticker].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting the close column on the last position\n",
    "df=df[['Date',\n",
    "'p_sentiment',\n",
    " 'Open',\n",
    " 'High',\n",
    " 'Low',\n",
    " 'unrate',\n",
    " 'psr',\n",
    " 'm2',\n",
    " 'dspic',\n",
    " 'pce',\n",
    " 'reer',\n",
    " 'ir',\n",
    " 'ffer',\n",
    " 'tcs',\n",
    " 'indpro',\n",
    " 'ccpi',\n",
    "  'Close',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p_sentiment',\n",
       " 'Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'unrate',\n",
       " 'psr',\n",
       " 'm2',\n",
       " 'dspic',\n",
       " 'pce',\n",
       " 'reer',\n",
       " 'ir',\n",
       " 'ffer',\n",
       " 'tcs',\n",
       " 'indpro',\n",
       " 'ccpi',\n",
       " 'Close']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=list(df)[1:]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_training = df[cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95039792 0.10635442 0.09772617 ... 0.77924797 0.         0.0943931 ]\n",
      " [0.67576714 0.09094073 0.08393475 ... 0.77924797 0.         0.07908343]\n",
      " [0.73744721 0.08223946 0.0779041  ... 0.77924797 0.         0.07913316]\n",
      " ...\n",
      " [0.49456218 0.96867548 0.98027688 ... 0.57323507 1.         0.9919973 ]\n",
      " [0.71490676 1.         1.         ... 0.57323507 1.         0.99145044]\n",
      " [0.68512664 0.9917462  0.99367278 ... 0.57323507 1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split scaled data into training, val and testing\n",
    "#train_data=scaled_data[0:1000,:]\n",
    "#val_data=scaled_data[1000:1125,:]\n",
    "#test_data=scaled_data[1125:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future = 1 # Number of days we want to predict into the future\n",
    "n_past = 7 # Number of past days we want to use to predict the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for i in range(n_past, len(scaled_data) - n_future +1):\n",
    "    X.append(scaled_data[i - n_past:i, 0:df_for_training.shape[1]])\n",
    "    y.append(scaled_data[i + n_future - 1:i + n_future, len(cols)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1245, 7, 16)\n",
      "(1245, 1)\n"
     ]
    }
   ],
   "source": [
    "#shape of X_s and y_s\n",
    "X, y = np.array(X), np.array(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X[0:1200,:]\n",
    "X_test=X[1200:,:]\n",
    "y_train=y[0:1200,:]\n",
    "y_test=y[1200:,:]\n",
    "\n",
    "#early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 21:31:29.949785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 21:31:30.043504: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 21:31:30.043541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 21:31:30.045808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 21:31:30.045843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 21:31:30.045861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 21:31:30.683148: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 21:31:30.683199: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 21:31:30.683203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-25 21:31:30.683230: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 21:31:30.683244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9330 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TransformerEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/j/usfq/tesis/StockPredictionModels/Models/GRU/GRU_TF.ipynb Cell 19\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/j/usfq/tesis/StockPredictionModels/Models/GRU/GRU_TF.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m y_train, y_val \u001b[39m=\u001b[39m y[train_index], y[val_index]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/j/usfq/tesis/StockPredictionModels/Models/GRU/GRU_TF.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m=\u001b[39mSequential()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/j/usfq/tesis/StockPredictionModels/Models/GRU/GRU_TF.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39madd(TransformerEncoder(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/j/usfq/tesis/StockPredictionModels/Models/GRU/GRU_TF.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m num_heads\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m,  \u001b[39m# Specify the number of attention heads\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/j/usfq/tesis/StockPredictionModels/Models/GRU/GRU_TF.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m units\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m,  \u001b[39m# Specify the number of hidden units\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/j/usfq/tesis/StockPredictionModels/Models/GRU/GRU_TF.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m input_shape\u001b[39m=\u001b[39m(X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], X_train\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/j/usfq/tesis/StockPredictionModels/Models/GRU/GRU_TF.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(y_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/j/usfq/tesis/StockPredictionModels/Models/GRU/GRU_TF.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TransformerEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "y_test=np.repeat(y_test,16,axis=1)\n",
    "y_test=scaler.inverse_transform(y_test)[:,-1] \n",
    "for train_index, val_index in tscv.split(X_train):\n",
    "    early_stop=EarlyStopping(monitor='val_loss',patience=10)\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    model=Sequential()\n",
    "    model.add(GRU(2048, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))\n",
    "    model.add(Dense(y_train.shape[1]))\n",
    "    model.compile(optimizer='adam',loss='mse')\n",
    "  \n",
    "    history=model.fit(X_train,y_train,epochs=100,validation_data=(X_val,y_val),shuffle=False, callbacks=[early_stop])\n",
    "    plt.plot(history.history['loss'],label='train')\n",
    "    plt.plot(history.history['val_loss'],label='val')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    y_pred=model.predict(X_test)\n",
    "    y_pred.shape\n",
    "\n",
    "    pred=np.repeat(y_pred,16,axis=1)\n",
    "\n",
    "    pred=scaler.inverse_transform(pred)[:,-1]\n",
    "    \n",
    "\n",
    "    print(pred.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "    #plotting the results\n",
    "    plt.plot(y_test, label='real')\n",
    "    plt.plot(pred, label='pred') \n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
