{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pylab as rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import matplotlib \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5319,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>p_sentiment</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>unrate</th>\n",
       "      <th>psr</th>\n",
       "      <th>m2</th>\n",
       "      <th>dspic</th>\n",
       "      <th>pce</th>\n",
       "      <th>reer</th>\n",
       "      <th>ir</th>\n",
       "      <th>ffer</th>\n",
       "      <th>tcs</th>\n",
       "      <th>indpro</th>\n",
       "      <th>ccpi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>27.847500</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>26.837500</td>\n",
       "      <td>27.332500</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>15.629000</td>\n",
       "      <td>15.737500</td>\n",
       "      <td>15.348000</td>\n",
       "      <td>15.426000</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.883473</td>\n",
       "      <td>26.378078</td>\n",
       "      <td>26.490770</td>\n",
       "      <td>26.133251</td>\n",
       "      <td>26.168653</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.908735</td>\n",
       "      <td>26.629999</td>\n",
       "      <td>26.790001</td>\n",
       "      <td>26.393999</td>\n",
       "      <td>26.477501</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.804051</td>\n",
       "      <td>46.660000</td>\n",
       "      <td>47.419998</td>\n",
       "      <td>46.540001</td>\n",
       "      <td>46.759998</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7531</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.748412</td>\n",
       "      <td>93.699997</td>\n",
       "      <td>94.199997</td>\n",
       "      <td>92.030998</td>\n",
       "      <td>92.344498</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.676151</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>67.650002</td>\n",
       "      <td>66.700996</td>\n",
       "      <td>66.806999</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.705876</td>\n",
       "      <td>67.840500</td>\n",
       "      <td>67.849998</td>\n",
       "      <td>66.891998</td>\n",
       "      <td>66.985497</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.762997</td>\n",
       "      <td>158.990005</td>\n",
       "      <td>159.020004</td>\n",
       "      <td>156.729996</td>\n",
       "      <td>157.589996</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.588330</td>\n",
       "      <td>28.586000</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>27.284000</td>\n",
       "      <td>27.646667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7536 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date ticker_symbol  p_sentiment        Open        High  \\\n",
       "0     2015-01-02          AAPL     0.857156   27.847500   27.860001   \n",
       "1     2015-01-02          AMZN     0.731959   15.629000   15.737500   \n",
       "2     2015-01-02          GOOG     0.883473   26.378078   26.490770   \n",
       "3     2015-01-02         GOOGL     0.908735   26.629999   26.790001   \n",
       "4     2015-01-02          MSFT     0.804051   46.660000   47.419998   \n",
       "...          ...           ...          ...         ...         ...   \n",
       "7531  2019-12-30          AMZN     0.748412   93.699997   94.199997   \n",
       "7532  2019-12-30          GOOG     0.676151   67.500000   67.650002   \n",
       "7533  2019-12-30         GOOGL     0.705876   67.840500   67.849998   \n",
       "7534  2019-12-30          MSFT     0.762997  158.990005  159.020004   \n",
       "7535  2019-12-30          TSLA     0.588330   28.586000   28.600000   \n",
       "\n",
       "             Low       Close  unrate  psr       m2    dspic      pce    reer  \\\n",
       "0      26.837500   27.332500     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "1      15.348000   15.426000     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "2      26.133251   26.168653     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "3      26.393999   26.477501     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "4      46.540001   46.759998     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "...          ...         ...     ...  ...      ...      ...      ...     ...   \n",
       "7531   92.030998   92.344498     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7532   66.700996   66.806999     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7533   66.891998   66.985497     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7534  156.729996  157.589996     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7535   27.284000   27.646667     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "\n",
       "            ir      ffer        tcs    indpro     ccpi  \n",
       "0     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "1     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "2     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "3     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "4     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "...        ...       ...        ...       ...      ...  \n",
       "7531  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7532  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7533  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7534  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7535  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "\n",
       "[7536 rows x 18 columns]"
      ]
     },
     "execution_count": 5321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/home/j/usfq/tesis/StockPredictionModels/Data/Complete.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>p_sentiment</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>unrate</th>\n",
       "      <th>psr</th>\n",
       "      <th>m2</th>\n",
       "      <th>dspic</th>\n",
       "      <th>pce</th>\n",
       "      <th>reer</th>\n",
       "      <th>ir</th>\n",
       "      <th>ffer</th>\n",
       "      <th>tcs</th>\n",
       "      <th>indpro</th>\n",
       "      <th>ccpi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.420157e+09</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>27.847500</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>26.837500</td>\n",
       "      <td>27.332500</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.420157e+09</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>15.629000</td>\n",
       "      <td>15.737500</td>\n",
       "      <td>15.348000</td>\n",
       "      <td>15.426000</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.420157e+09</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.883473</td>\n",
       "      <td>26.378078</td>\n",
       "      <td>26.490770</td>\n",
       "      <td>26.133251</td>\n",
       "      <td>26.168653</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.420157e+09</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.908735</td>\n",
       "      <td>26.629999</td>\n",
       "      <td>26.790001</td>\n",
       "      <td>26.393999</td>\n",
       "      <td>26.477501</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.420157e+09</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.804051</td>\n",
       "      <td>46.660000</td>\n",
       "      <td>47.419998</td>\n",
       "      <td>46.540001</td>\n",
       "      <td>46.759998</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7531</th>\n",
       "      <td>1.577664e+09</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.748412</td>\n",
       "      <td>93.699997</td>\n",
       "      <td>94.199997</td>\n",
       "      <td>92.030998</td>\n",
       "      <td>92.344498</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>1.577664e+09</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.676151</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>67.650002</td>\n",
       "      <td>66.700996</td>\n",
       "      <td>66.806999</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>1.577664e+09</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.705876</td>\n",
       "      <td>67.840500</td>\n",
       "      <td>67.849998</td>\n",
       "      <td>66.891998</td>\n",
       "      <td>66.985497</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>1.577664e+09</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.762997</td>\n",
       "      <td>158.990005</td>\n",
       "      <td>159.020004</td>\n",
       "      <td>156.729996</td>\n",
       "      <td>157.589996</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>1.577664e+09</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.588330</td>\n",
       "      <td>28.586000</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>27.284000</td>\n",
       "      <td>27.646667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7536 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date ticker_symbol  p_sentiment        Open        High  \\\n",
       "0     1.420157e+09          AAPL     0.857156   27.847500   27.860001   \n",
       "1     1.420157e+09          AMZN     0.731959   15.629000   15.737500   \n",
       "2     1.420157e+09          GOOG     0.883473   26.378078   26.490770   \n",
       "3     1.420157e+09         GOOGL     0.908735   26.629999   26.790001   \n",
       "4     1.420157e+09          MSFT     0.804051   46.660000   47.419998   \n",
       "...            ...           ...          ...         ...         ...   \n",
       "7531  1.577664e+09          AMZN     0.748412   93.699997   94.199997   \n",
       "7532  1.577664e+09          GOOG     0.676151   67.500000   67.650002   \n",
       "7533  1.577664e+09         GOOGL     0.705876   67.840500   67.849998   \n",
       "7534  1.577664e+09          MSFT     0.762997  158.990005  159.020004   \n",
       "7535  1.577664e+09          TSLA     0.588330   28.586000   28.600000   \n",
       "\n",
       "             Low       Close  unrate  psr       m2    dspic      pce    reer  \\\n",
       "0      26.837500   27.332500     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "1      15.348000   15.426000     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "2      26.133251   26.168653     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "3      26.393999   26.477501     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "4      46.540001   46.759998     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "...          ...         ...     ...  ...      ...      ...      ...     ...   \n",
       "7531   92.030998   92.344498     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7532   66.700996   66.806999     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7533   66.891998   66.985497     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7534  156.729996  157.589996     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7535   27.284000   27.646667     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "\n",
       "            ir      ffer        tcs    indpro     ccpi  \n",
       "0     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "1     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "2     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "3     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "4     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "...        ...       ...        ...       ...      ...  \n",
       "7531  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7532  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7533  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7534  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7535  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "\n",
       "[7536 rows x 18 columns]"
      ]
     },
     "execution_count": 5322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn date into unix time\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date'] = df['Date'].apply(lambda x: x.timestamp())\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only use date, open, high, low, close\n",
    "#df = df[['Date', 'ticker_symbol','p_sentiment','unrate','m2','Open', 'High', 'Low', 'Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL (1252, 16)\n",
      "      p_sentiment       Open       High        Low      Close  unrate  psr  \\\n",
      "0        0.857156  27.847500  27.860001  26.837500  27.332500     5.7  8.0   \n",
      "1        0.744531  27.072500  27.162500  26.352501  26.562500     5.7  8.0   \n",
      "2        0.769826  26.635000  26.857500  26.157499  26.565001     5.7  8.0   \n",
      "3        0.773995  26.799999  27.049999  26.674999  26.937500     5.7  8.0   \n",
      "4        0.770458  27.307501  28.037500  27.174999  27.972500     5.7  8.0   \n",
      "...           ...        ...        ...        ...        ...     ...  ...   \n",
      "1246     0.775477  70.557503  70.662498  69.639999  69.860001     3.6  7.3   \n",
      "1247     0.759453  70.132500  71.062500  70.092499  71.000000     3.6  7.3   \n",
      "1248     0.742264  71.172501  71.222504  70.730003  71.067497     3.6  7.3   \n",
      "1249     0.670220  71.205002  72.495003  71.175003  72.477501     3.6  7.3   \n",
      "1250     0.760582  72.779999  73.492500  72.029999  72.449997     3.6  7.3   \n",
      "\n",
      "           m2    dspic      pce    reer        ir      ffer        tcs  \\\n",
      "0     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "1     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "2     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "3     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "4     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "...       ...      ...      ...     ...       ...       ...        ...   \n",
      "1246  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1247  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1248  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1249  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1250  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "\n",
      "        indpro     ccpi  \n",
      "0     102.8479  239.811  \n",
      "1     102.8479  239.811  \n",
      "2     102.8479  239.811  \n",
      "3     102.8479  239.811  \n",
      "4     102.8479  239.811  \n",
      "...        ...      ...  \n",
      "1246  101.6179  265.651  \n",
      "1247  101.6179  265.651  \n",
      "1248  101.6179  265.651  \n",
      "1249  101.6179  265.651  \n",
      "1250  101.6179  265.651  \n",
      "\n",
      "[1251 rows x 16 columns]\n",
      "AMZN (1257, 16)\n",
      "      p_sentiment       Open       High        Low      Close  unrate  psr  \\\n",
      "0        0.731959  15.629000  15.737500  15.348000  15.426000     5.7  8.0   \n",
      "1        0.696571  15.350500  15.419000  15.042500  15.109500     5.7  8.0   \n",
      "2        0.640295  15.112000  15.150000  14.619000  14.764500     5.7  8.0   \n",
      "3        0.654047  14.875000  15.064000  14.766500  14.921000     5.7  8.0   \n",
      "4        0.653703  15.016000  15.157000  14.805500  15.023000     5.7  8.0   \n",
      "...           ...        ...        ...        ...        ...     ...  ...   \n",
      "1251     0.713209  89.981003  90.148499  89.122498  89.324997     3.6  7.3   \n",
      "1252     0.788889  89.413002  89.650002  89.225502  89.650002     3.6  7.3   \n",
      "1253     0.749017  89.690498  89.778503  89.378998  89.460503     3.6  7.3   \n",
      "1254     0.765611  90.050499  93.523003  89.974998  93.438499     3.6  7.3   \n",
      "1255     0.738419  94.146004  95.070000  93.300499  93.489998     3.6  7.3   \n",
      "\n",
      "           m2    dspic      pce    reer        ir      ffer        tcs  \\\n",
      "0     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "1     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "2     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "3     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "4     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "...       ...      ...      ...     ...       ...       ...        ...   \n",
      "1251  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1252  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1253  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1254  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1255  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "\n",
      "        indpro     ccpi  \n",
      "0     102.8479  239.811  \n",
      "1     102.8479  239.811  \n",
      "2     102.8479  239.811  \n",
      "3     102.8479  239.811  \n",
      "4     102.8479  239.811  \n",
      "...        ...      ...  \n",
      "1251  101.6179  265.651  \n",
      "1252  101.6179  265.651  \n",
      "1253  101.6179  265.651  \n",
      "1254  101.6179  265.651  \n",
      "1255  101.6179  265.651  \n",
      "\n",
      "[1256 rows x 16 columns]\n",
      "GOOG (1256, 16)\n",
      "      p_sentiment       Open       High        Low      Close  unrate  psr  \\\n",
      "0        0.883473  26.378078  26.490770  26.133251  26.168653     5.7  8.0   \n",
      "1        0.842274  26.091366  26.144720  25.582764  25.623152     5.7  8.0   \n",
      "2        0.767560  25.679497  25.738087  24.983908  25.029282     5.7  8.0   \n",
      "3        0.726427  25.280592  25.292759  24.914099  24.986401     5.7  8.0   \n",
      "4        0.814441  24.831326  25.105074  24.482782  25.065184     5.7  8.0   \n",
      "...           ...        ...        ...        ...        ...     ...  ...   \n",
      "1250     0.670623  68.167503  68.181999  67.449997  67.479500     3.6  7.3   \n",
      "1251     0.774953  67.793503  67.989998  67.325500  67.442001     3.6  7.3   \n",
      "1252     0.698763  67.425003  67.513000  67.139000  67.178001     3.6  7.3   \n",
      "1253     0.797474  67.308502  68.066353  67.223503  68.019997     3.6  7.3   \n",
      "1254     0.738640  68.149498  68.226501  67.465500  67.594498     3.6  7.3   \n",
      "\n",
      "           m2    dspic      pce    reer        ir      ffer        tcs  \\\n",
      "0     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "1     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "2     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "3     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "4     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "...       ...      ...      ...     ...       ...       ...        ...   \n",
      "1250  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1251  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1252  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1253  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1254  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "\n",
      "        indpro     ccpi  \n",
      "0     102.8479  239.811  \n",
      "1     102.8479  239.811  \n",
      "2     102.8479  239.811  \n",
      "3     102.8479  239.811  \n",
      "4     102.8479  239.811  \n",
      "...        ...      ...  \n",
      "1250  101.6179  265.651  \n",
      "1251  101.6179  265.651  \n",
      "1252  101.6179  265.651  \n",
      "1253  101.6179  265.651  \n",
      "1254  101.6179  265.651  \n",
      "\n",
      "[1255 rows x 16 columns]\n",
      "GOOGL (1257, 16)\n",
      "      p_sentiment       Open       High        Low      Close  unrate  psr  \\\n",
      "0        0.908735  26.629999  26.790001  26.393999  26.477501     5.7  8.0   \n",
      "1        0.882317  26.357500  26.399500  25.887501  25.973000     5.7  8.0   \n",
      "2        0.791379  26.025000  26.060499  25.277500  25.332001     5.7  8.0   \n",
      "3        0.721880  25.547501  25.574499  25.182501  25.257500     5.7  8.0   \n",
      "4        0.730047  25.075500  25.375000  24.750999  25.345501     5.7  8.0   \n",
      "...           ...        ...        ...        ...        ...     ...  ...   \n",
      "1251     0.768590  68.154999  68.199997  67.536499  67.560997     3.6  7.3   \n",
      "1252     0.716898  67.936501  68.092499  67.400002  67.531502     3.6  7.3   \n",
      "1253     0.764184  67.510498  67.600502  67.208504  67.221497     3.6  7.3   \n",
      "1254     0.826140  67.327499  68.160004  67.275497  68.123497     3.6  7.3   \n",
      "1255     0.698837  68.199997  68.352501  67.650002  67.732002     3.6  7.3   \n",
      "\n",
      "           m2    dspic      pce    reer        ir      ffer        tcs  \\\n",
      "0     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "1     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "2     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "3     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "4     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "...       ...      ...      ...     ...       ...       ...        ...   \n",
      "1251  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1252  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1253  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1254  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1255  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "\n",
      "        indpro     ccpi  \n",
      "0     102.8479  239.811  \n",
      "1     102.8479  239.811  \n",
      "2     102.8479  239.811  \n",
      "3     102.8479  239.811  \n",
      "4     102.8479  239.811  \n",
      "...        ...      ...  \n",
      "1251  101.6179  265.651  \n",
      "1252  101.6179  265.651  \n",
      "1253  101.6179  265.651  \n",
      "1254  101.6179  265.651  \n",
      "1255  101.6179  265.651  \n",
      "\n",
      "[1256 rows x 16 columns]\n",
      "MSFT (1257, 16)\n",
      "      p_sentiment        Open        High         Low       Close  unrate  \\\n",
      "0        0.804051   46.660000   47.419998   46.540001   46.759998     5.7   \n",
      "1        0.777896   46.369999   46.730000   46.250000   46.330002     5.7   \n",
      "2        0.757679   46.380001   46.750000   45.540001   45.650002     5.7   \n",
      "3        0.870317   45.980000   46.459999   45.490002   46.230000     5.7   \n",
      "4        0.797476   46.750000   47.750000   46.720001   47.590000     5.7   \n",
      "...           ...         ...         ...         ...         ...     ...   \n",
      "1251     0.733492  157.350006  158.490005  156.289993  157.410004     3.6   \n",
      "1252     0.741044  158.119995  158.119995  157.270004  157.410004     3.6   \n",
      "1253     0.680918  157.479996  157.710007  157.119995  157.380005     3.6   \n",
      "1254     0.727596  157.559998  158.729996  157.399994  158.669998     3.6   \n",
      "1255     0.757561  159.449997  159.550003  158.220001  158.960007     3.6   \n",
      "\n",
      "      psr       m2    dspic      pce    reer        ir      ffer        tcs  \\\n",
      "0     8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "1     8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "2     8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "3     8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "4     8.0  11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "...   ...      ...      ...      ...     ...       ...       ...        ...   \n",
      "1251  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1252  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1253  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1254  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1255  7.3  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "\n",
      "        indpro     ccpi  \n",
      "0     102.8479  239.811  \n",
      "1     102.8479  239.811  \n",
      "2     102.8479  239.811  \n",
      "3     102.8479  239.811  \n",
      "4     102.8479  239.811  \n",
      "...        ...      ...  \n",
      "1251  101.6179  265.651  \n",
      "1252  101.6179  265.651  \n",
      "1253  101.6179  265.651  \n",
      "1254  101.6179  265.651  \n",
      "1255  101.6179  265.651  \n",
      "\n",
      "[1256 rows x 16 columns]\n",
      "TSLA (1257, 16)\n",
      "      p_sentiment       Open       High        Low      Close  unrate  psr  \\\n",
      "0        0.741818  14.858000  14.883333  14.217333  14.620667     5.7  8.0   \n",
      "1        0.646626  14.303333  14.433333  13.810667  14.006000     5.7  8.0   \n",
      "2        0.696584  14.004000  14.280000  13.614000  14.085333     5.7  8.0   \n",
      "3        0.654833  14.223333  14.318667  13.985333  14.063333     5.7  8.0   \n",
      "4        0.615611  14.187333  14.253333  14.000667  14.041333     5.7  8.0   \n",
      "...           ...        ...        ...        ...        ...     ...  ...   \n",
      "1251     0.586239  27.352667  27.533333  26.679333  27.039333     3.6  7.3   \n",
      "1252     0.589381  27.452000  28.134001  27.333332  27.948000     3.6  7.3   \n",
      "1253     0.643900  27.890667  28.364668  27.512667  28.350000     3.6  7.3   \n",
      "1254     0.601846  28.527332  28.898666  28.423332  28.729334     3.6  7.3   \n",
      "1255     0.563272  29.000000  29.020666  28.407333  28.691999     3.6  7.3   \n",
      "\n",
      "           m2    dspic      pce    reer        ir      ffer        tcs  \\\n",
      "0     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "1     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "2     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "3     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "4     11759.1  13224.7  12036.5  106.11  1.881500  0.114839  1069010.0   \n",
      "...       ...      ...      ...     ...       ...       ...        ...   \n",
      "1251  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1252  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1253  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1254  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "1255  15416.2  14844.1  14686.3  116.51  1.862857  1.550968  1458485.0   \n",
      "\n",
      "        indpro     ccpi  \n",
      "0     102.8479  239.811  \n",
      "1     102.8479  239.811  \n",
      "2     102.8479  239.811  \n",
      "3     102.8479  239.811  \n",
      "4     102.8479  239.811  \n",
      "...        ...      ...  \n",
      "1251  101.6179  265.651  \n",
      "1252  101.6179  265.651  \n",
      "1253  101.6179  265.651  \n",
      "1254  101.6179  265.651  \n",
      "1255  101.6179  265.651  \n",
      "\n",
      "[1256 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "#generate new dataframes for each ticker_symbol\n",
    "df_dict={}\n",
    "for key in df['ticker_symbol'].unique():\n",
    "    df_dict[key]=df[df['ticker_symbol']==key]\n",
    "    df_dict[key]=df_dict[key].drop(columns=['ticker_symbol'])\n",
    "    df_dict[key]=df_dict[key].sort_values(by=['Date']).reset_index(drop=True)\n",
    "    df_dict[key]=df_dict[key].drop(columns=['Date'])\n",
    "    print(key,df_dict[key].shape)\n",
    "    print(df_dict[key].head(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5325,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker='AAPL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5326,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler(feature_range=(-1,1))\n",
    "scaler=scaler.fit(df_dict[ticker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[ticker]=pd.DataFrame(scaler.transform(df_dict[ticker]), columns=df_dict[ticker].columns, index=df_dict[ticker].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 16) (1000, 16) (126, 16)\n"
     ]
    }
   ],
   "source": [
    "train_size=int(len(df_dict[ticker])*0.9)\n",
    "train_df, test_df=df_dict[ticker][:train_size], df_dict[ticker][train_size:]\n",
    "train_df,val_df=train_df[:int(len(train_df)-126)],train_df[int(len(train_df)-126):]\n",
    "print(val_df.shape, train_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_sentiment</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>unrate</th>\n",
       "      <th>psr</th>\n",
       "      <th>m2</th>\n",
       "      <th>dspic</th>\n",
       "      <th>pce</th>\n",
       "      <th>reer</th>\n",
       "      <th>ir</th>\n",
       "      <th>ffer</th>\n",
       "      <th>tcs</th>\n",
       "      <th>indpro</th>\n",
       "      <th>ccpi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.049956</td>\n",
       "      <td>-0.335123</td>\n",
       "      <td>-0.342659</td>\n",
       "      <td>-0.394312</td>\n",
       "      <td>-0.399642</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.472631</td>\n",
       "      <td>0.799422</td>\n",
       "      <td>0.52019</td>\n",
       "      <td>0.550035</td>\n",
       "      <td>0.61215</td>\n",
       "      <td>0.870751</td>\n",
       "      <td>0.109083</td>\n",
       "      <td>0.899874</td>\n",
       "      <td>0.552786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.175050</td>\n",
       "      <td>-0.421738</td>\n",
       "      <td>-0.408008</td>\n",
       "      <td>-0.424918</td>\n",
       "      <td>-0.438413</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.472631</td>\n",
       "      <td>0.799422</td>\n",
       "      <td>0.52019</td>\n",
       "      <td>0.550035</td>\n",
       "      <td>0.61215</td>\n",
       "      <td>0.870751</td>\n",
       "      <td>0.109083</td>\n",
       "      <td>0.899874</td>\n",
       "      <td>0.552786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.007977</td>\n",
       "      <td>-0.420247</td>\n",
       "      <td>-0.351854</td>\n",
       "      <td>-0.423609</td>\n",
       "      <td>-0.335620</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.472631</td>\n",
       "      <td>0.799422</td>\n",
       "      <td>0.52019</td>\n",
       "      <td>0.550035</td>\n",
       "      <td>0.61215</td>\n",
       "      <td>0.870751</td>\n",
       "      <td>0.109083</td>\n",
       "      <td>0.899874</td>\n",
       "      <td>0.552786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.181035</td>\n",
       "      <td>-0.345267</td>\n",
       "      <td>-0.356401</td>\n",
       "      <td>-0.389882</td>\n",
       "      <td>-0.345760</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.472631</td>\n",
       "      <td>0.799422</td>\n",
       "      <td>0.52019</td>\n",
       "      <td>0.550035</td>\n",
       "      <td>0.61215</td>\n",
       "      <td>0.870751</td>\n",
       "      <td>0.109083</td>\n",
       "      <td>0.899874</td>\n",
       "      <td>0.552786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.393293</td>\n",
       "      <td>-0.328759</td>\n",
       "      <td>-0.339100</td>\n",
       "      <td>-0.344777</td>\n",
       "      <td>-0.344965</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.472631</td>\n",
       "      <td>0.799422</td>\n",
       "      <td>0.52019</td>\n",
       "      <td>0.550035</td>\n",
       "      <td>0.61215</td>\n",
       "      <td>0.870751</td>\n",
       "      <td>0.109083</td>\n",
       "      <td>0.899874</td>\n",
       "      <td>0.552786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     p_sentiment      Open      High       Low     Close    unrate  psr  \\\n",
       "995    -0.049956 -0.335123 -0.342659 -0.394312 -0.399642 -0.636364  1.0   \n",
       "996    -0.175050 -0.421738 -0.408008 -0.424918 -0.438413 -0.636364  1.0   \n",
       "997     0.007977 -0.420247 -0.351854 -0.423609 -0.335620 -0.636364  1.0   \n",
       "998     0.181035 -0.345267 -0.356401 -0.389882 -0.345760 -0.636364  1.0   \n",
       "999     0.393293 -0.328759 -0.339100 -0.344777 -0.344965 -0.636364  1.0   \n",
       "\n",
       "           m2     dspic      pce      reer       ir      ffer       tcs  \\\n",
       "995  0.472631  0.799422  0.52019  0.550035  0.61215  0.870751  0.109083   \n",
       "996  0.472631  0.799422  0.52019  0.550035  0.61215  0.870751  0.109083   \n",
       "997  0.472631  0.799422  0.52019  0.550035  0.61215  0.870751  0.109083   \n",
       "998  0.472631  0.799422  0.52019  0.550035  0.61215  0.870751  0.109083   \n",
       "999  0.472631  0.799422  0.52019  0.550035  0.61215  0.870751  0.109083   \n",
       "\n",
       "       indpro      ccpi  \n",
       "995  0.899874  0.552786  \n",
       "996  0.899874  0.552786  \n",
       "997  0.899874  0.552786  \n",
       "998  0.899874  0.552786  \n",
       "999  0.899874  0.552786  "
      ]
     },
     "execution_count": 5329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display last 5 rows\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(input_data: pd.DataFrame, target_column, sequence_length):\n",
    "    sequences=[]\n",
    "    data_size=len(input_data)\n",
    "\n",
    "    for i in tqdm(range(data_size-sequence_length)):\n",
    "        sequence=input_data[i:i+sequence_length].copy()\n",
    "        label_position=i+sequence_length\n",
    "        label=input_data.iloc[label_position][target_column]\n",
    "        sequences.append((sequence, label))\n",
    "    return sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113860c9a7d44ed492d7d018fe65c8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bd4e76319b4afca7696d2ebdc43fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8cb344589e44c8832936995462d579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEQUENCE_LENGTH=20\n",
    "#consider changing to high and low\n",
    "train_sequences=create_sequences(train_df, 'Close', SEQUENCE_LENGTH)\n",
    "test_sequences=create_sequences(test_df, 'Close', SEQUENCE_LENGTH)\n",
    "val_sequences=create_sequences(val_df, 'Close', SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5332,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences=sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sequence, label=self.sequences[index]\n",
    "        return dict(\n",
    "            sequence=torch.Tensor(sequence.to_numpy()),\n",
    "            label=torch.Tensor([label]).float()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_sequences, test_sequences, val_sequences, batch_size=128):\n",
    "        super().__init__()\n",
    "        self.train_sequences=train_sequences\n",
    "        self.test_sequences=test_sequences\n",
    "        self.val_sequences=val_sequences\n",
    "        self.batch_size=batch_size\n",
    "\n",
    "    def setup(self,stage=None):\n",
    "        self.train_dataset=StockDataset(self.train_sequences)\n",
    "        self.test_dataset=StockDataset(self.test_sequences)\n",
    "        self.val_dataset=StockDataset(self.val_sequences)\n",
    "\n",
    "    def train_dataloader(self): #considerar el shuffle\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True,num_workers=2)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False,num_workers=1)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5334,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS=1024\n",
    "BATCH_SIZE=128\n",
    "\n",
    "data_module=StockDataModule(train_sequences, test_sequences, val_sequences, batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5335,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=StockDataset(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16])\n",
      "torch.Size([1])\n",
      "tensor([-0.7188])\n"
     ]
    }
   ],
   "source": [
    "for item in train_dataset:\n",
    "    print(item['sequence'].shape)\n",
    "    print(item['label'].shape)\n",
    "    print(item['label'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete checkpoints and lightning_logs\n",
    "import os\n",
    "import shutil\n",
    "shutil.rmtree('/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/lightning_logs')\n",
    "shutil.rmtree('/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden=12, n_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #self.lstm = nn.LSTM(input_size=n_features, hidden_size=n_hidden, num_layers=n_layers, \n",
    "         #                   batch_first=True, dropout=dropout if n_layers > 1 else 0)\n",
    "          # GRU can be an alternative for LSTM\n",
    "        self.lstm = nn.GRU(input_size=n_features, hidden_size=n_hidden, num_layers=n_layers, \n",
    "                            batch_first=True, dropout=dropout if n_layers > 1 else 0)\n",
    "\n",
    "        # Weight initialization for LSTM\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                torch.nn.init.xavier_uniform_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                torch.nn.init.orthogonal_(param.data)\n",
    "                \n",
    "        self.linear = nn.Linear(in_features=n_hidden, out_features=1)\n",
    "\n",
    "        # GRU can be an alternative for LSTM\n",
    "        # self.lstm = nn.GRU(input_size=n_features, hidden_size=n_hidden, num_layers=n_layers, \n",
    "        #                    batch_first=True, dropout=dropout if n_layers > 1 else 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.lstm.flatten_parameters()\n",
    "        output, hidden = self.lstm(x)\n",
    "        return self.linear(output[:, -1, :])  # taking the last timestep's output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5339,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockLSTM(pl.LightningModule):\n",
    "    def __init__(self, n_features, l1_strength=1e-5, l2_strength=1e-4):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.model = LSTM_Model(n_features)\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # L1 and L2 regularization strengths\n",
    "        self.l1_strength = l1_strength\n",
    "        self.l2_strength = l2_strength\n",
    "\n",
    "    def l1_regularization(self, model):\n",
    "        return sum(torch.norm(param, 1) for param in model.parameters())\n",
    "\n",
    "\n",
    "    def l2_regularization(self, model):\n",
    "        return sum(torch.norm(param, 2) for param in model.parameters())\n",
    "\n",
    "    \n",
    "    def forward(self, x, labels=None):\n",
    "        output = self.model(x)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "            \n",
    "            # Apply L1 and L2 regularization\n",
    "            loss += self.l1_strength * self.l1_regularization(self.model)\n",
    "            loss += self.l2_strength * self.l2_regularization(self.model)\n",
    "            \n",
    "        return loss, output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch['sequence'], batch['label']\n",
    "        loss, outputs = self(x, y)\n",
    "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def on_after_backward(self):\n",
    "        if self.trainer.global_step % self.trainer.log_every_n_steps == 0:\n",
    "            for name, params in self.named_parameters():\n",
    "                self.logger.experiment.add_histogram(name, params.grad, self.trainer.global_step)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'val_loss'}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch['sequence'], batch['label']\n",
    "        loss, outputs = self(x, y)\n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch['sequence'], batch['label']\n",
    "        loss, outputs = self(x, y)\n",
    "        self.log('test_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def predict(self, x, y):\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        return y_hat, loss\n",
    "\n",
    "    def save_model(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 16)"
      ]
     },
     "execution_count": 5340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5341,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StockLSTM(n_features=train_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20, 16])\n",
      "torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "for item in data_module.train_dataloader():\n",
    "    print(item['sequence'].shape)\n",
    "    print(item['label'].shape)\n",
    "    #print(item['label'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5343,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback=pl.callbacks.ModelCheckpoint(\n",
    "    dirpath='checkpoints',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "logger=pl.loggers.TensorBoardLogger('lightning_logs/', name='stock-lstm')\n",
    "\n",
    "early_stopping_callback=pl.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback,early_stopping_callback],\n",
    "    max_epochs=N_EPOCHS,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: lightning_logs/stock-lstm\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | model     | LSTM_Model | 1.1 K \n",
      "-----------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c0a58ce54548f19c765729a16ff427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/miniconda3/envs/gen/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/j/miniconda3/envs/gen/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([106, 1, 1])) that is different to the input size (torch.Size([106, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/j/miniconda3/envs/gen/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac08fbeb97745f1a011418f07baf252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/miniconda3/envs/gen/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([128, 1, 1])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/j/miniconda3/envs/gen/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([84, 1, 1])) that is different to the input size (torch.Size([84, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e213ada5993f4befba7ba43a7a468321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 8: 'val_loss' reached 0.06397 (best 0.06397), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124fb568f4ed4bf28052f3a1c10a0708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 16: 'val_loss' reached 0.05332 (best 0.05332), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356247d33ea54f158cb41a3dd574434f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 24: 'val_loss' reached 0.03859 (best 0.03859), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f6440b3fe34872b8558c6699dffcd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 32: 'val_loss' reached 0.02649 (best 0.02649), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0c36176ee84f3f9026b9b541f2a01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 40: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ad58cae49c4a92a26077a999f3a09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 48: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5895378fee404d82a3b38ebac4130b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 56: 'val_loss' was not in top 1\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5345,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model=StockLSTM.load_from_checkpoint('checkpoints/best-checkpoint.ckpt', n_features=test_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5346,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ae01db68ee46ad8afd62f66fcaa7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset=StockDataset(test_sequences)\n",
    "\n",
    "predictions = []\n",
    "labels=[]\n",
    "\n",
    "trained_model.to('cpu') # move the model to the CPU\n",
    "\n",
    "for item in tqdm(test_dataset):\n",
    "    x=item['sequence']\n",
    "    y=item['label']\n",
    "   \n",
    "    _, output= trained_model(x.unsqueeze(dim=0)) # send input to the device\n",
    "    predictions.append(output.item())\n",
    "    labels.append(y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 106)"
      ]
     },
     "execution_count": 5348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions),len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106,) (106,)\n",
      "(106, 1) (106, 1)\n",
      "(106, 16) (106, 16)\n"
     ]
    }
   ],
   "source": [
    "#turn predictions and labels into numpy arrays of shape 112,16\n",
    "predictions=np.array(predictions)\n",
    "labels=np.array(labels)\n",
    "print(predictions.shape,labels.shape)\n",
    "\n",
    "#reshape predictions and labels to 2d arrays\n",
    "predictions=predictions.reshape(-1,1)\n",
    "labels=labels.reshape(-1,1)\n",
    "print(predictions.shape,labels.shape)\n",
    "\n",
    "predictions= np.repeat(predictions, repeats=16, axis=1)\n",
    "labels= np.repeat(labels, repeats=16, axis=1)\n",
    "print(predictions.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unnormalize predictions and labels with sclaer for only the Close column\n",
    "predictions_list=scaler.inverse_transform(predictions)\n",
    "labels_list=scaler.inverse_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106, 16) (106, 16)\n"
     ]
    }
   ],
   "source": [
    "#show shape of predictions and labels\n",
    "print(predictions_list.shape,labels_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106,) (106,)\n"
     ]
    }
   ],
   "source": [
    "predictions_list=predictions_list[:,4]\n",
    "labels_list=labels_list[:,4]\n",
    "print(predictions_list.shape,labels_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 106)"
      ]
     },
     "execution_count": 5353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences_data= val_df.iloc[SEQUENCE_LENGTH:].copy()\n",
    "len(test_sequences_data),len(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dates=matplotlib.dates.date2num(test_sequences_data.index)\n",
    "plt.plot_date(dates, predictions_list, \"-\", label=\"Predictions\")\n",
    "plt.plot_date(dates, labels_list, \"-\", label=\"Actual\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 500790), started 1:17:32 ago. (Use '!kill 500790' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
