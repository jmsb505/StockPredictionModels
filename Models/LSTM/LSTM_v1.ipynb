{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1537,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pylab as rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import matplotlib \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1538,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1539,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>p_sentiment</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>unrate</th>\n",
       "      <th>psr</th>\n",
       "      <th>m2</th>\n",
       "      <th>dspic</th>\n",
       "      <th>pce</th>\n",
       "      <th>reer</th>\n",
       "      <th>ir</th>\n",
       "      <th>ffer</th>\n",
       "      <th>tcs</th>\n",
       "      <th>indpro</th>\n",
       "      <th>ccpi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>27.847500</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>26.837500</td>\n",
       "      <td>27.332500</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>15.629000</td>\n",
       "      <td>15.737500</td>\n",
       "      <td>15.348000</td>\n",
       "      <td>15.426000</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.883473</td>\n",
       "      <td>26.378078</td>\n",
       "      <td>26.490770</td>\n",
       "      <td>26.133251</td>\n",
       "      <td>26.168653</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.908735</td>\n",
       "      <td>26.629999</td>\n",
       "      <td>26.790001</td>\n",
       "      <td>26.393999</td>\n",
       "      <td>26.477501</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.804051</td>\n",
       "      <td>46.660000</td>\n",
       "      <td>47.419998</td>\n",
       "      <td>46.540001</td>\n",
       "      <td>46.759998</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7531</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.748412</td>\n",
       "      <td>93.699997</td>\n",
       "      <td>94.199997</td>\n",
       "      <td>92.030998</td>\n",
       "      <td>92.344498</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.676151</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>67.650002</td>\n",
       "      <td>66.700996</td>\n",
       "      <td>66.806999</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.705876</td>\n",
       "      <td>67.840500</td>\n",
       "      <td>67.849998</td>\n",
       "      <td>66.891998</td>\n",
       "      <td>66.985497</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.762997</td>\n",
       "      <td>158.990005</td>\n",
       "      <td>159.020004</td>\n",
       "      <td>156.729996</td>\n",
       "      <td>157.589996</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.588330</td>\n",
       "      <td>28.586000</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>27.284000</td>\n",
       "      <td>27.646667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7536 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date ticker_symbol  p_sentiment        Open        High  \\\n",
       "0     2015-01-02          AAPL     0.857156   27.847500   27.860001   \n",
       "1     2015-01-02          AMZN     0.731959   15.629000   15.737500   \n",
       "2     2015-01-02          GOOG     0.883473   26.378078   26.490770   \n",
       "3     2015-01-02         GOOGL     0.908735   26.629999   26.790001   \n",
       "4     2015-01-02          MSFT     0.804051   46.660000   47.419998   \n",
       "...          ...           ...          ...         ...         ...   \n",
       "7531  2019-12-30          AMZN     0.748412   93.699997   94.199997   \n",
       "7532  2019-12-30          GOOG     0.676151   67.500000   67.650002   \n",
       "7533  2019-12-30         GOOGL     0.705876   67.840500   67.849998   \n",
       "7534  2019-12-30          MSFT     0.762997  158.990005  159.020004   \n",
       "7535  2019-12-30          TSLA     0.588330   28.586000   28.600000   \n",
       "\n",
       "             Low       Close  unrate  psr       m2    dspic      pce    reer  \\\n",
       "0      26.837500   27.332500     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "1      15.348000   15.426000     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "2      26.133251   26.168653     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "3      26.393999   26.477501     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "4      46.540001   46.759998     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "...          ...         ...     ...  ...      ...      ...      ...     ...   \n",
       "7531   92.030998   92.344498     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7532   66.700996   66.806999     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7533   66.891998   66.985497     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7534  156.729996  157.589996     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7535   27.284000   27.646667     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "\n",
       "            ir      ffer        tcs    indpro     ccpi  \n",
       "0     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "1     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "2     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "3     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "4     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "...        ...       ...        ...       ...      ...  \n",
       "7531  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7532  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7533  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7534  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7535  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "\n",
       "[7536 rows x 18 columns]"
      ]
     },
     "execution_count": 1540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/home/j/usfq/tesis/StockPredictionModels/Data/Complete.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>p_sentiment</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>unrate</th>\n",
       "      <th>psr</th>\n",
       "      <th>m2</th>\n",
       "      <th>dspic</th>\n",
       "      <th>pce</th>\n",
       "      <th>reer</th>\n",
       "      <th>ir</th>\n",
       "      <th>ffer</th>\n",
       "      <th>tcs</th>\n",
       "      <th>indpro</th>\n",
       "      <th>ccpi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.420157e+09</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>27.847500</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>26.837500</td>\n",
       "      <td>27.332500</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.420157e+09</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>15.629000</td>\n",
       "      <td>15.737500</td>\n",
       "      <td>15.348000</td>\n",
       "      <td>15.426000</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.420157e+09</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.883473</td>\n",
       "      <td>26.378078</td>\n",
       "      <td>26.490770</td>\n",
       "      <td>26.133251</td>\n",
       "      <td>26.168653</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.420157e+09</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.908735</td>\n",
       "      <td>26.629999</td>\n",
       "      <td>26.790001</td>\n",
       "      <td>26.393999</td>\n",
       "      <td>26.477501</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.420157e+09</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.804051</td>\n",
       "      <td>46.660000</td>\n",
       "      <td>47.419998</td>\n",
       "      <td>46.540001</td>\n",
       "      <td>46.759998</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11759.1</td>\n",
       "      <td>13224.7</td>\n",
       "      <td>12036.5</td>\n",
       "      <td>106.11</td>\n",
       "      <td>1.881500</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>1069010.0</td>\n",
       "      <td>102.8479</td>\n",
       "      <td>239.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7531</th>\n",
       "      <td>1.577664e+09</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.748412</td>\n",
       "      <td>93.699997</td>\n",
       "      <td>94.199997</td>\n",
       "      <td>92.030998</td>\n",
       "      <td>92.344498</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>1.577664e+09</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.676151</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>67.650002</td>\n",
       "      <td>66.700996</td>\n",
       "      <td>66.806999</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>1.577664e+09</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.705876</td>\n",
       "      <td>67.840500</td>\n",
       "      <td>67.849998</td>\n",
       "      <td>66.891998</td>\n",
       "      <td>66.985497</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>1.577664e+09</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.762997</td>\n",
       "      <td>158.990005</td>\n",
       "      <td>159.020004</td>\n",
       "      <td>156.729996</td>\n",
       "      <td>157.589996</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>1.577664e+09</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.588330</td>\n",
       "      <td>28.586000</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>27.284000</td>\n",
       "      <td>27.646667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15416.2</td>\n",
       "      <td>14844.1</td>\n",
       "      <td>14686.3</td>\n",
       "      <td>116.51</td>\n",
       "      <td>1.862857</td>\n",
       "      <td>1.550968</td>\n",
       "      <td>1458485.0</td>\n",
       "      <td>101.6179</td>\n",
       "      <td>265.651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7536 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date ticker_symbol  p_sentiment        Open        High  \\\n",
       "0     1.420157e+09          AAPL     0.857156   27.847500   27.860001   \n",
       "1     1.420157e+09          AMZN     0.731959   15.629000   15.737500   \n",
       "2     1.420157e+09          GOOG     0.883473   26.378078   26.490770   \n",
       "3     1.420157e+09         GOOGL     0.908735   26.629999   26.790001   \n",
       "4     1.420157e+09          MSFT     0.804051   46.660000   47.419998   \n",
       "...            ...           ...          ...         ...         ...   \n",
       "7531  1.577664e+09          AMZN     0.748412   93.699997   94.199997   \n",
       "7532  1.577664e+09          GOOG     0.676151   67.500000   67.650002   \n",
       "7533  1.577664e+09         GOOGL     0.705876   67.840500   67.849998   \n",
       "7534  1.577664e+09          MSFT     0.762997  158.990005  159.020004   \n",
       "7535  1.577664e+09          TSLA     0.588330   28.586000   28.600000   \n",
       "\n",
       "             Low       Close  unrate  psr       m2    dspic      pce    reer  \\\n",
       "0      26.837500   27.332500     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "1      15.348000   15.426000     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "2      26.133251   26.168653     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "3      26.393999   26.477501     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "4      46.540001   46.759998     5.7  8.0  11759.1  13224.7  12036.5  106.11   \n",
       "...          ...         ...     ...  ...      ...      ...      ...     ...   \n",
       "7531   92.030998   92.344498     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7532   66.700996   66.806999     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7533   66.891998   66.985497     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7534  156.729996  157.589996     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "7535   27.284000   27.646667     3.6  7.3  15416.2  14844.1  14686.3  116.51   \n",
       "\n",
       "            ir      ffer        tcs    indpro     ccpi  \n",
       "0     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "1     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "2     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "3     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "4     1.881500  0.114839  1069010.0  102.8479  239.811  \n",
       "...        ...       ...        ...       ...      ...  \n",
       "7531  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7532  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7533  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7534  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "7535  1.862857  1.550968  1458485.0  101.6179  265.651  \n",
       "\n",
       "[7536 rows x 18 columns]"
      ]
     },
     "execution_count": 1541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn date into unix time\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date'] = df['Date'].apply(lambda x: x.timestamp())\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1542,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only use date, open, high, low, close\n",
    "#df = df[['Date', 'ticker_symbol','p_sentiment','unrate','m2','Open', 'High', 'Low', 'Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL (1252, 16)\n",
      "   p_sentiment     Open       High        Low      Close  unrate  psr  \\\n",
      "0     0.857156  27.8475  27.860001  26.837500  27.332500     5.7  8.0   \n",
      "1     0.744531  27.0725  27.162500  26.352501  26.562500     5.7  8.0   \n",
      "2     0.769826  26.6350  26.857500  26.157499  26.565001     5.7  8.0   \n",
      "\n",
      "        m2    dspic      pce    reer      ir      ffer        tcs    indpro  \\\n",
      "0  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "1  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "2  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "\n",
      "      ccpi  \n",
      "0  239.811  \n",
      "1  239.811  \n",
      "2  239.811  \n",
      "AMZN (1257, 16)\n",
      "   p_sentiment     Open     High      Low    Close  unrate  psr       m2  \\\n",
      "0     0.731959  15.6290  15.7375  15.3480  15.4260     5.7  8.0  11759.1   \n",
      "1     0.696571  15.3505  15.4190  15.0425  15.1095     5.7  8.0  11759.1   \n",
      "2     0.640295  15.1120  15.1500  14.6190  14.7645     5.7  8.0  11759.1   \n",
      "\n",
      "     dspic      pce    reer      ir      ffer        tcs    indpro     ccpi  \n",
      "0  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479  239.811  \n",
      "1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479  239.811  \n",
      "2  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479  239.811  \n",
      "GOOG (1256, 16)\n",
      "   p_sentiment       Open       High        Low      Close  unrate  psr  \\\n",
      "0     0.883473  26.378078  26.490770  26.133251  26.168653     5.7  8.0   \n",
      "1     0.842274  26.091366  26.144720  25.582764  25.623152     5.7  8.0   \n",
      "2     0.767560  25.679497  25.738087  24.983908  25.029282     5.7  8.0   \n",
      "\n",
      "        m2    dspic      pce    reer      ir      ffer        tcs    indpro  \\\n",
      "0  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "1  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "2  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "\n",
      "      ccpi  \n",
      "0  239.811  \n",
      "1  239.811  \n",
      "2  239.811  \n",
      "GOOGL (1257, 16)\n",
      "   p_sentiment       Open       High        Low      Close  unrate  psr  \\\n",
      "0     0.908735  26.629999  26.790001  26.393999  26.477501     5.7  8.0   \n",
      "1     0.882317  26.357500  26.399500  25.887501  25.973000     5.7  8.0   \n",
      "2     0.791379  26.025000  26.060499  25.277500  25.332001     5.7  8.0   \n",
      "\n",
      "        m2    dspic      pce    reer      ir      ffer        tcs    indpro  \\\n",
      "0  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "1  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "2  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "\n",
      "      ccpi  \n",
      "0  239.811  \n",
      "1  239.811  \n",
      "2  239.811  \n",
      "MSFT (1257, 16)\n",
      "   p_sentiment       Open       High        Low      Close  unrate  psr  \\\n",
      "0     0.804051  46.660000  47.419998  46.540001  46.759998     5.7  8.0   \n",
      "1     0.777896  46.369999  46.730000  46.250000  46.330002     5.7  8.0   \n",
      "2     0.757679  46.380001  46.750000  45.540001  45.650002     5.7  8.0   \n",
      "\n",
      "        m2    dspic      pce    reer      ir      ffer        tcs    indpro  \\\n",
      "0  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "1  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "2  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "\n",
      "      ccpi  \n",
      "0  239.811  \n",
      "1  239.811  \n",
      "2  239.811  \n",
      "TSLA (1257, 16)\n",
      "   p_sentiment       Open       High        Low      Close  unrate  psr  \\\n",
      "0     0.741818  14.858000  14.883333  14.217333  14.620667     5.7  8.0   \n",
      "1     0.646626  14.303333  14.433333  13.810667  14.006000     5.7  8.0   \n",
      "2     0.696584  14.004000  14.280000  13.614000  14.085333     5.7  8.0   \n",
      "\n",
      "        m2    dspic      pce    reer      ir      ffer        tcs    indpro  \\\n",
      "0  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "1  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "2  11759.1  13224.7  12036.5  106.11  1.8815  0.114839  1069010.0  102.8479   \n",
      "\n",
      "      ccpi  \n",
      "0  239.811  \n",
      "1  239.811  \n",
      "2  239.811  \n"
     ]
    }
   ],
   "source": [
    "#generate new dataframes for each ticker_symbol\n",
    "df_dict={}\n",
    "for key in df['ticker_symbol'].unique():\n",
    "    df_dict[key]=df[df['ticker_symbol']==key]\n",
    "    df_dict[key]=df_dict[key].drop(columns=['ticker_symbol'])\n",
    "    df_dict[key]=df_dict[key].sort_values(by=['Date']).reset_index(drop=True)\n",
    "    df_dict[key]=df_dict[key].drop(columns=['Date'])\n",
    "    print(key,df_dict[key].shape)\n",
    "    print(df_dict[key].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 16) (1000, 16) (126, 16)\n",
      "(126, 16) (1005, 16) (126, 16)\n",
      "(126, 16) (1004, 16) (126, 16)\n",
      "(126, 16) (1005, 16) (126, 16)\n",
      "(126, 16) (1005, 16) (126, 16)\n",
      "(126, 16) (1005, 16) (126, 16)\n"
     ]
    }
   ],
   "source": [
    "train_df_dict={}\n",
    "test_df_dict={}\n",
    "val_df_dict={}\n",
    "for key in df_dict.keys():\n",
    "    train_size=int(len(df_dict[key])*0.9)\n",
    "    train_df_dict[key], test_df_dict[key]=df_dict[key][:train_size], df_dict[key][train_size:]\n",
    "    train_df_dict[key],val_df_dict[key]=train_df_dict[key][:int(len(train_df_dict[key])-126)],train_df_dict[key][int(len(train_df_dict[key])-126):]\n",
    "    print(val_df_dict[key].shape, train_df_dict[key].shape, test_df_dict[key].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker='AAPL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df_dict[ticker]\n",
    "test_df=test_df_dict[ticker]\n",
    "val_df=val_df_dict[ticker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1547,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "scaler=scaler.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_sentiment</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>unrate</th>\n",
       "      <th>psr</th>\n",
       "      <th>m2</th>\n",
       "      <th>dspic</th>\n",
       "      <th>pce</th>\n",
       "      <th>reer</th>\n",
       "      <th>ir</th>\n",
       "      <th>ffer</th>\n",
       "      <th>tcs</th>\n",
       "      <th>indpro</th>\n",
       "      <th>ccpi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950398</td>\n",
       "      <td>0.151939</td>\n",
       "      <td>0.139422</td>\n",
       "      <td>0.127432</td>\n",
       "      <td>0.133987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229028</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.779248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.675767</td>\n",
       "      <td>0.129919</td>\n",
       "      <td>0.119746</td>\n",
       "      <td>0.113606</td>\n",
       "      <td>0.112256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229028</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.779248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.737447</td>\n",
       "      <td>0.117488</td>\n",
       "      <td>0.111142</td>\n",
       "      <td>0.108046</td>\n",
       "      <td>0.112326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229028</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.779248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.747614</td>\n",
       "      <td>0.122176</td>\n",
       "      <td>0.116573</td>\n",
       "      <td>0.122799</td>\n",
       "      <td>0.122839</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229028</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.779248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.738988</td>\n",
       "      <td>0.136596</td>\n",
       "      <td>0.144429</td>\n",
       "      <td>0.137054</td>\n",
       "      <td>0.152050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229028</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.779248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_sentiment      Open      High       Low     Close  unrate  psr   m2  \\\n",
       "0     0.950398  0.151939  0.139422  0.127432  0.133987     1.0  0.6  0.0   \n",
       "1     0.675767  0.129919  0.119746  0.113606  0.112256     1.0  0.6  0.0   \n",
       "2     0.737447  0.117488  0.111142  0.108046  0.112326     1.0  0.6  0.0   \n",
       "3     0.747614  0.122176  0.116573  0.122799  0.122839     1.0  0.6  0.0   \n",
       "4     0.738988  0.136596  0.144429  0.137054  0.152050     1.0  0.6  0.0   \n",
       "\n",
       "   dspic  pce  reer        ir      ffer  tcs    indpro  ccpi  \n",
       "0    0.0  0.0   0.0  0.229028  0.001906  0.0  0.779248   0.0  \n",
       "1    0.0  0.0   0.0  0.229028  0.001906  0.0  0.779248   0.0  \n",
       "2    0.0  0.0   0.0  0.229028  0.001906  0.0  0.779248   0.0  \n",
       "3    0.0  0.0   0.0  0.229028  0.001906  0.0  0.779248   0.0  \n",
       "4    0.0  0.0   0.0  0.229028  0.001906  0.0  0.779248   0.0  "
      ]
     },
     "execution_count": 1548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.DataFrame(scaler.transform(train_df), columns=train_df.columns, index=train_df.index)\n",
    "test_df=pd.DataFrame(scaler.transform(test_df), columns=test_df.columns, index=test_df.index)\n",
    "val_df=pd.DataFrame(scaler.transform(val_df), columns=val_df.columns, index=val_df.index)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1549,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(input_data: pd.DataFrame, target_column, sequence_length):\n",
    "    sequences=[]\n",
    "    data_size=len(input_data)\n",
    "\n",
    "    for i in tqdm(range(data_size-sequence_length)):\n",
    "        sequence=input_data[i:i+sequence_length].copy()\n",
    "        label_position=i+sequence_length\n",
    "        label=input_data.iloc[label_position][target_column]\n",
    "        sequences.append((sequence, label))\n",
    "    return sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a550f38c92ca49418b00d449d7fe9d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a7da8499b44a8d9807b589b3a84912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d9c22d878c46e0adda817c63e6d353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEQUENCE_LENGTH=14\n",
    "#consider changing to high and low\n",
    "train_sequences=create_sequences(train_df, 'Close', SEQUENCE_LENGTH)\n",
    "test_sequences=create_sequences(test_df, 'Close', SEQUENCE_LENGTH)\n",
    "val_sequences=create_sequences(val_df, 'Close', SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1551,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences=sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sequence, label=self.sequences[index]\n",
    "        return dict(\n",
    "            sequence=torch.Tensor(sequence.to_numpy()),\n",
    "            label=torch.Tensor([label]).float()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1552,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_sequences, test_sequences, val_sequences, batch_size=128):\n",
    "        super().__init__()\n",
    "        self.train_sequences=train_sequences\n",
    "        self.test_sequences=test_sequences\n",
    "        self.val_sequences=val_sequences\n",
    "        self.batch_size=batch_size\n",
    "\n",
    "    def setup(self,stage=None):\n",
    "        self.train_dataset=StockDataset(self.train_sequences)\n",
    "        self.test_dataset=StockDataset(self.test_sequences)\n",
    "        self.val_dataset=StockDataset(self.val_sequences)\n",
    "\n",
    "    def train_dataloader(self): #considerar el shuffle\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True,num_workers=2)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=1, shuffle=False,num_workers=1)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=1, shuffle=False,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1553,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS=1024\n",
    "BATCH_SIZE=256\n",
    "\n",
    "data_module=StockDataModule(train_sequences, test_sequences, val_sequences, batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1554,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=StockDataset(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 16])\n",
      "torch.Size([1])\n",
      "tensor([0.1597])\n"
     ]
    }
   ],
   "source": [
    "for item in train_dataset:\n",
    "    print(item['sequence'].shape)\n",
    "    print(item['label'].shape)\n",
    "    print(item['label'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden=128, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.n_hidden=n_hidden\n",
    "        self.n_layers=n_layers\n",
    "        self.lstm=nn.LSTM(input_size=n_features, hidden_size=n_hidden, num_layers=n_layers, batch_first=True,)\n",
    "        self.linear=nn.Linear(in_features=n_hidden, out_features=1) #considerar cambiar a 2\n",
    "\n",
    "    def forward(self,x):\n",
    "        self.lstm.flatten_parameters()\n",
    "        _, (hidden, _)= self.lstm(x)\n",
    "        out= hidden[-1]\n",
    "\n",
    "        return self.linear(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1557,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockLSTM(pl.LightningModule):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.criterion=nn.MSELoss()\n",
    "        self.model=LSTM_Model(n_features)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        output= self.model(x)\n",
    "        loss=0\n",
    "        if labels is not None:\n",
    "            loss=self.criterion(output, labels.unsqueeze(dim=1))\n",
    "        return loss, output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x=batch['sequence']\n",
    "        y=batch['label']\n",
    "        loss, outputs= self(x, y)\n",
    "        self.log('train_loss', loss,prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=0.0001)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x=batch['sequence']\n",
    "        y=batch['label']\n",
    "        loss, outputs= self(x, y)\n",
    "        self.log('val_loss', loss,prog_bar=True, logger=True)\n",
    "        return  loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x=batch['sequence']\n",
    "        y=batch['label']\n",
    "        loss, outputs= self(x, y)\n",
    "        self.log('test_loss', loss,prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def predict(self, x, y):\n",
    "        y_hat=self(x).squeeze()\n",
    "        loss=self.loss(y_hat, y)\n",
    "        return y_hat, loss\n",
    "\n",
    "    def save_model(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 16)"
      ]
     },
     "execution_count": 1558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1559,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StockLSTM(n_features=train_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 14, 16])\n",
      "torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "for item in data_module.train_dataloader():\n",
    "    print(item['sequence'].shape)\n",
    "    print(item['label'].shape)\n",
    "    #print(item['label'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1561,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback=pl.callbacks.ModelCheckpoint(\n",
    "    dirpath='checkpoints',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=3,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "logger=pl.loggers.TensorBoardLogger('lightning_logs/', name='stock-lstm')\n",
    "\n",
    "early_stopping_callback=pl.callbacks.EarlyStopping(monitor='val_loss', patience=3,verbose=False,mode='min')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    callbacks=[ checkpoint_callback,early_stopping_callback],\n",
    "    max_epochs=N_EPOCHS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1562,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: lightning_logs/stock-lstm\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | model     | LSTM_Model | 206 K \n",
      "-----------------------------------------\n",
      "206 K     Trainable params\n",
      "0         Non-trainable params\n",
      "206 K     Total params\n",
      "0.828     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e455c5b0c4684e6db6a959173de108b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/miniconda3/envs/gen/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/home/j/miniconda3/envs/gen/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/j/miniconda3/envs/gen/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a651681260a4188ba45a4ceadc7ff91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/miniconda3/envs/gen/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 1, 1])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/j/miniconda3/envs/gen/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([218, 1, 1])) that is different to the input size (torch.Size([218, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2e6b33136343ddbda50b454cbc0d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 4: 'val_loss' reached 0.36710 (best 0.36710), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520efa92a29e4442a0f846ee7a75c211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 8: 'val_loss' reached 0.33324 (best 0.33324), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint-v1.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a4d115c599480882550d6589884b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 12: 'val_loss' reached 0.29976 (best 0.29976), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint-v2.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8484b3b504454bb0ae00188d90ed6c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 16: 'val_loss' reached 0.26609 (best 0.26609), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706f2909d91849b496d2e214eac00677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 20: 'val_loss' reached 0.23187 (best 0.23187), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint-v1.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca154f1fe1b4ec9bc0d4dac9d3b7793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 24: 'val_loss' reached 0.19659 (best 0.19659), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint-v2.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7280e726b1bc4cb9a3c93f1b7643f9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 28: 'val_loss' reached 0.16079 (best 0.16079), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df782c5cf4884dbf885513b8afb7399e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 32: 'val_loss' reached 0.12495 (best 0.12495), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint-v1.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1350eb870b1c400bbc06b8f8df9bbd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 36: 'val_loss' reached 0.09221 (best 0.09221), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint-v2.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812130899d564816ae29a017d838fb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 40: 'val_loss' reached 0.06687 (best 0.06687), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4add95b7d51f45f49326e1426eae2f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 44: 'val_loss' reached 0.05258 (best 0.05258), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint-v1.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ef4f5f6840477185abb7f3edd551cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 48: 'val_loss' reached 0.05107 (best 0.05107), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint-v2.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5255ad870d24f69ac7240fb1394b78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 52: 'val_loss' reached 0.05887 (best 0.05107), saving model to '/home/j/usfq/tesis/StockPredictionModels/Models/LSTM/checkpoints/best-checkpoint.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107c90adbffa4372b8e0b05fe4aa7df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 56: 'val_loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea606c4d5c24c81b43d2affe2eb7f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 60: 'val_loss' was not in top 3\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1563,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model=StockLSTM.load_from_checkpoint('checkpoints/best-checkpoint-v1.ckpt', n_features=test_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1564,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed08a5a068b4116b841eaeea86b2f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset=StockDataset(test_sequences)\n",
    "\n",
    "predictions = []\n",
    "labels=[]\n",
    "\n",
    "trained_model.to('cpu') # move the model to the CPU\n",
    "\n",
    "for item in tqdm(test_dataset):\n",
    "    x=item['sequence']\n",
    "    y=item['label']\n",
    "   \n",
    "    _, output= trained_model(x.unsqueeze(dim=0)) # send input to the device\n",
    "    predictions.append(output.item())\n",
    "    labels.append(y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 112)"
      ]
     },
     "execution_count": 1566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions),len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1567,
   "metadata": {},
   "outputs": [],
   "source": [
    "descaler=MinMaxScaler(feature_range=(0,1))\n",
    "descaler.min_,descaler.scale_=scaler.min_[-1],scaler.scale_[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1568,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale(descaler,values):\n",
    "    values_2d=np.array(values)[:, np.newaxis]\n",
    "    return descaler.inverse_transform(values_2d).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1569,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1  # for the second column as an example\n",
    "feature_min = scaler.data_min_[4]\n",
    "feature_max = scaler.data_max_[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1570,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_feature(feature_normalized, feature_min, feature_max):\n",
    "    return feature_normalized * (feature_max - feature_min) + feature_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1571,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = denormalize_feature(np.array(predictions), feature_min, feature_max)\n",
    "labels = denormalize_feature(np.array(labels), feature_min, feature_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 84465), started 2:04:29 ago. (Use '!kill 84465' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
